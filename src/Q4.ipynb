{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_error(y, y_pred):\n",
    "    m = len(y)\n",
    "    return np.sum(np.square(y - y_pred))/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Boston-filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# # Create train and test set\n",
    "# train = df[:m_train].reset_index(drop=True)\n",
    "# test = df[m_train:].reset_index(drop=True)\n",
    "\n",
    "# train_y = train.iloc[:, -1]\n",
    "# train_X = train.iloc[:, :-1]\n",
    "\n",
    "# test_y = test.iloc[:, -1]\n",
    "# test_X = test.iloc[:, :-1]\n",
    "\n",
    "# train_ones_x = np.ones(m_train)\n",
    "# test_ones_x = np.ones(m - m_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lr(X_train, y_train):\n",
    "    w = np.linalg.inv(X_train.T@X_train)@X_train.T@y_train\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lr(X_test, y_test, w):\n",
    "    y_pred = X_test@w\n",
    "    error = mean_square_error(y_test, y_pred)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_set(D, train_ratio):\n",
    "    m = len(D)\n",
    "    m_train = int(train_ratio * m // 1)\n",
    "    \n",
    "    np.random.shuffle(D)\n",
    "\n",
    "    train = D[:m_train]\n",
    "    test = D[m_train:]\n",
    "\n",
    "    X_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    \n",
    "    X_test = test[:, :-1]\n",
    "    y_test = test[:, -1]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr(df, mode='single', variable=1, iterations=20, precision=3):\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    \n",
    "    D = df.to_numpy()\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        X_train, y_train, X_test, y_test = create_train_test_set(D, 2/3)\n",
    "\n",
    "        if mode == 'ones':\n",
    "            X_train = np.ones(len(X_train)).reshape(-1, 1)\n",
    "            X_test = np.ones(len(X_test)).reshape(-1, 1)\n",
    "\n",
    "        elif mode == 'single':\n",
    "            X_train = X_train[:, variable].reshape(-1, 1)\n",
    "            X_train = np.hstack( (X_train, np.ones(len(X_train)).reshape(-1, 1)) )\n",
    "            X_test = X_test[:, variable].reshape(-1, 1)\n",
    "            X_test = np.hstack( (X_test, np.ones(len(X_test)).reshape(-1, 1)) )\n",
    "        \n",
    "        w = train_lr(X_train, y_train)\n",
    "        \n",
    "        train_error = evaluate_lr(X_train, y_train, w)\n",
    "        test_error = evaluate_lr(X_test, y_test, w)\n",
    "\n",
    "        train_errors.append(train_error)\n",
    "        test_errors.append(test_error)\n",
    "    \n",
    "    train_mean = round(np.mean(np.array(train_errors)), precision)\n",
    "    train_std = round(np.std(np.array(train_errors)), precision)\n",
    "\n",
    "    test_mean = round(np.mean(np.array(test_errors)), precision)\n",
    "    test_std = round(np.std(np.array(test_errors)), precision)\n",
    "            \n",
    "    return train_errors, test_errors, train_mean, train_std, test_mean, test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_errors, test_errors, train_means, train_stds, test_means, test_stds = lr(df, mode='ones', precision = 3)\n",
    "print(f\"Train and Test MSE over 20 runs for Naive Regression: {train_means}, {test_means}\")\n",
    "print(f\"std over 20 runs for Naive Regression: {train_stds}, {test_stds}\")\n",
    "print('\\n')\n",
    "\n",
    "for i in range(df.shape[-1] - 1):\n",
    "    train_errors, test_errors, train_means, train_stds, test_means, test_stds = lr(df, mode='single', variable=i, iterations=20)\n",
    "    \n",
    "    print(f\"MSE over 20 runs for {df.columns[i]}: {train_means}, {test_means}\")\n",
    "    print(f\"std over 20 runs for {df.columns[i]}: {train_stds}, {test_stds}\")\n",
    "    print('\\n')\n",
    "\n",
    "train_errors, test_errors, train_means, train_stds, test_means, test_stds = lr(df, mode='full')\n",
    "print(f\"Train and Test MSE over 20 runs with full dataset: {train_means}, {test_means}\")\n",
    "print(f\"Train and Test std over 20 runs with full dataset: {train_stds}, {test_stds}\")\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
